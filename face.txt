1.卷积的特点 
	局部连接 权值共享，下采样
2不同的卷积层都提取什么类型特征
	浅层：提取边缘特征
	中层：提取局部特征
	深层：提取全局特征
3.卷积的size变化
	(h - k + p + s)/s
4.1x1卷积的作用
	1.对特征图的通道数进行升维或降维，降维时减少模型参数量
	2.1x1卷积＋激活函数， 增加网络的非线性，提升网络表达能力
5.转置卷积的作用
	对特征图进行上采样或扩张
		1.语义分割
		2.物体检测中需要输出与原图像大小一致的图
	size： w = s*(n - 1) + k - 2p  (p为单边padding )
6.转置卷积的棋盘效应是什么
	原因： 转置卷积的不均匀叠加导致的图像中某个部位的颜色比其他部分更深
	解决办法： 双线性插值 和 近邻插值
7.空洞卷积的作用
	在不进行池化操作损失信息情况下，增大感受野，让每个卷积输出都包含较大范围的信息
	获取多尺度上下文信息，当带有不同扩展率的空洞卷积核叠加时， 不同感受野会带来多尺度信息
	卷积核size变化：k = k + (k - 1)*(d - 1)
8.感受野的作用
	一般来说感受野越大越好
	感受野足够大时，忽略的信息就较少
	目标检测任务中，设置 的anchor要对其感受野， anchor太大或偏离感受野会对性能产生影响
9.感受野的计算
	RF_n = RF_n-1 + （k - 1）* (stride的乘积)
10.如何增大感受野
	1.使用空洞卷积
	2.使用池化层
	3.增大卷积核
11.简述分组卷积
	1.分组卷积最早出现于alexnet，用于切分网络，使得能够在多个GPU上并行运算
	好处：1-减少参数量
		2-可以堪称稀疏操作，可以在较少的参数量情况下可以获得更好的效果
	缺点：对内存的访问成都并未降低，且现有gpu加速库优化成都有限，因此效率提升的效果并不如理论上
12.简述常见的激活函数， sigmoid， tanh， relu
13.如何提升CNN模型的泛化能力
	1.采集更多数据
	2.优化数据分布，使得数据类别均衡
	3.数据增强
	4.优化网络结构
	5.选用合适优化器
14.BN层是什么，作用是什么，用在哪里
	批量归一化层用在卷积和激活函数之间
	作用：	可以选用较大的学习率，用于加速收敛
		使得分布更稳定
		防止过拟合
		解决梯度消失和梯度爆炸
	
15.BN层训练时为什么不使用整个数据集的均值和方差
	容易出现过拟合问题
16.如何解决类别不平衡问题
	1.过采样
	2.欠采样
	3.类别权重，给予少量类的的数据更高的权重
	4.数据增强
17.简述常见的优化器
	1.随机梯度下降SGD
	2.自适应梯度下降 Aaptive
	3.Adam
	SGD缺点是其更新方向完全依赖于当前batch计算出的梯度，因而十分不稳定。

	Adam的优点主要在于：

	考虑历史步中的梯度更新信息，能够降低梯度更新噪声。此外经过偏差校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。
	但是Adam也有其自身问题：可能会对前期出现的特征过拟合，后期才出现的特征很难纠正前期的拟合效果。二者似乎都没法很好避免局部最优问题。
18.iou是什么，如何计算
	交集/并集
19.目标检测中NMS相关概念和计算
	1.过滤score低于阈值的框
	2.选出概率最大的款
	3.与每个框计算iou，超过阈值则删除
	4.从剩下的候选框中选出score最大的值，重复上述操作
20.one-stage和two-stage的网络有什么区别，都有什么代表的网络
	1.two-stage网络先生成锚框，随后通过卷积网络等进行样本分类， 精读较高，速度较慢 R-CNN, Fast-RCNN，
	2.one-stage 不使用锚框，直接在网络中提取特征来预测物体的位置和分类，速度快， 精度稍低 yolo， ssd
21.提高小目标检测的效果的方法
	1.提高图像分辨率
	2.提高模型的输入分辨率
	3.平铺图像
22.ResNet模型的特点和解决的问题
	将模型的输入加到输出上， 解决随着模型深度加深，梯度变化不明显
23.yolov1的loss是什么，，yolov1的缺点
	1.由于YOLOv1每个网格的检测框只有2个，对于密集型目标检测和小物体检测都不能很好适用。
	2.Inference时，当同一类物体出现的不常见的长宽比时泛化能力偏弱。
	3.由于损失函数的问题，定位误差是影响检测效果的主要原因，尤其是大小物体的处理上，还有待加强。
24.yolov2中采用什么训练方法？多尺度训练的逻辑是什么
	多尺度训练（Multi-Scale Training）的逻辑是模型每训练一定的Epoch，改变输入图片的尺寸，使得模型对不同的输入尺寸更鲁棒，能够从容地对不同尺寸的图像进行检测。图像尺寸使用32的倍数
25.yolov2中loss是什么，
26.yolov2中anchor如何生成
	YOLOv2中引入K-means算法进行anchor的生成，可以自动找到更好的anchor宽高的值用于模型训练的初始化。如果使用经典K-means中的欧氏距离作为度量，意味着较大的Anchor会比较小的Anchor产生更大的误差，聚类结果可能会偏离。
由于目标检测中主要关心anchor与ground true box（gt box）的IOU，不关心两者的大小。因此，使用IOU作为度量更加合适，即提高IOU值。因此YOLOv2采用IOU值为评判标准
27.yolov2 anchor分类器使用什么分类器
28.yolov3引入了基础数据增强技术和高阶数据增强算法，有什么技术
	颜色变换：在色彩通道空间进行数据增强，比如将某种颜色通道关闭，或者改变亮度值。
	旋转变换：选择一个角度，左右旋转图像，可以改变图像内容朝向。
	添加噪声：从高斯等分布中采样出的随机值矩阵加入到图像中。
	锐化和模糊：使用高斯算子，拉普拉斯算子等处理图像。
	缩放变换：图像按照比例进行放大和缩小并不改变图像中的内容。
	平移变换：向上下左右四个维度移动图像。
	翻转变换：关于水平或者竖直的轴进行图像翻转操作。
	裁剪变换：主要有中心裁剪与随机裁剪。
	仿射变换：对图像进行一次线性变换并接上一个平移变换。
29.yolov3分类器使用是什么
Logistic分类器
30.Adam优化器的优势，实现原理
Adam优化器结合了AdaGrad和RMSProp两种优化算法的优点。对梯度的一阶矩估计（First Moment Estimation，即梯	度的均值）和二阶矩估计（Second Moment Estimation，即梯度的未中心化的方差）进行综合考虑，计算出更新步长。
	实现简单，计算高效，对内存需求少。
	参数的更新不受梯度的伸缩变换影响。
	超参数具有很好的解释性，且通常无需调整或仅需很少的微调。
	更新的步长能够被限制在大致的范围内（初始学习率）。
	能自然地实现步长退火过程（自动调整学习率）。
	很适合应用于大规模的数据及参数的场景。
	适用于不稳定目标函数。
	适用于梯度稀疏或梯度存在很大噪声的问题。
31.梯度下降的过程， 优缺点
	1.求梯度
	2.求梯度平均值
	3.更新权重
	优点：算法简介，收敛快，可以很快收敛到局部最优
	缺点：1.对超参数比较敏感， 学习率小了收敛过慢，学习率过大容易越过局部最优点
		2.容易卡在鞍点
		3.平坦区域梯度接近0，算法误判，提前结束迭代，线路局部最小值
	改进：从学习率和梯度方面改进
32.Momentum(带动量的梯度下降) 原理，优缺点
	优点：加速收敛，可以跳出局部最小值，鲁棒性更强
33.Adagrad 自适应学习率优化算法 原理
34.RMSProP 均方根传播原理
35.yolov4 输入端使用什么数据增强
	Masaic 和cutmix
36.Mosaic数据增强技术原理，有什么优点
	CutMix:使用两张图片分别选取部分像素进行拼接，产生新的数据
	Mosaic:使用四张图像采用随机缩放、裁剪和排布的方式进行拼接
	优点：1.优化模型对小目标的检测效果
		2.减少训练算力，由于可以一次性计算4张图片，所以Batchsize不用很大，
		3.让模型的鲁棒性与泛化性能更优
37.yolov4使用csp子模块的作用
CSP子模块主要解决了由于梯度信息重复导致的计算量庞大的问题。
提升模型的学习能力，同时使模型轻量化。
降低计算瓶颈，提高硬件利用率。
降低模型的内存占用。
38.IOU,GIOU,DIOU,CIOU  loss分别是什么 
iou = a交b/ aub
问题：1.bounding box 和ground truth不相交时， iou=0，无法反应两个框离得远近，进而导致iou loss不可导
	2.但两个bounding box 大小相同，iou相同时， iouloss无法区分两者位置
GIOU: 问题：当检测框再ground truth内部切检测款大小一致时， 无法区分相对位置关系
DIOU:问题： 当检测款再ground truth中，DIOU难以优化不同长宽比检测框他们再中心点一致的情况下

39.YOLOV5 有什么改进？ 
自适应图片缩放技术
	1.计算图像尺寸和输入尺寸的缩放比例，获得缩放后的图像尺寸
	2.进行自适应的填充，获得最后的输入图像
Backbone： 使用csp思想
head：引入自适应anchor box 和领域正负样本分配策略
	自适应anchor box： 自适应于训练数据， 根据不同训练数据自动学习适配相应的anchor box
	领域正负样本分配策略：1.将ground truth与当前feature map中的anchor box进行比较，如果ground truth与anchor 	box的宽高比例都处在 ，那么这个ground truth就能与当前featuer map相匹配。
	2、将当前feature map中的ground truth分配给对应的grid cell。将这个grid cell分为四个象限，针对与当前feature 	map匹配的ground truth，会计算该ground truth处于四个象限中的哪一个，并将邻近的两个grid cell中的检测框也作为	正样本。如下图所示，若ground truth偏向于右上角的象限，就会将ground truth所在grid cell的上面和右边的grid cell	中的检测框也作为正样本。
track：1.混合精度训练：尽可能减少精度损失的情况下利用FP16加速训练，并使用FP16存储模型权重，以此减少内存的占用，同时起到加速训练的效果
	2.模型EMA策略：将模型近期不同epoch参数做平均，提高模型整体检测性能以及鲁棒性
40.为什么yolo对小物体不敏感
	对小物体检测不敏感。因为虽然每个cell都可以预测出B个bounding box，
但是在最终只选择 IOU 最高的 bounding box 作为物体检测输出，即：每个 cell
只能预测出一个物体。当物体较小时，所占画面比例较小，比如图像中包含牲畜
群的时候，每个格子 kennel 包含多个物体，但是最后只能检测出其中的一个。
41.为什么yolo一个格子可以检测到大物体
	YOLO 并不是将图片分割成 单独的独立的 网格 分别 输入模型进行预
测，实际上，YOLO 网络最后的卷积层在原图上的感受野是远大于网格大小的，
网格只是用于物体中心位置归属哪个网格的划分
42.常见的边缘检测算子
Roberts算子,Sobel算子，Prewitt算子
43.介绍RCNN到faster rcnn
	1.r-cnn: 1.锚框选择，ROI池化层，将锚框均匀的切分成nxm块，输出每块中的最大值，总是输出nm个值 2。使用预训练模型对每个锚框抽取特征cnn 3.使用svm对类别分类4.训练一个线性回归模型来预测边缘框的偏移
	2.fast RCNN：1.使用cnn对原图抽取特征得到特征图 2. 在原图上选取锚框并将锚框映射到特征图上 3。使用ROI池化层对每个锚框生成固定长度特征
	3.faster RCNN：1.引入RPN模块生成候选框，取代selective search传统锚框生成方法
44.ssd单阶段目标检测算法 ont-stage