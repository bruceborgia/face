# 目录

## 一、Attention机制，Transformer面试问题汇总

- [1.Transformer Encoder 有什么子层？](#user-content)
- [2.Transformer self-attention的公式是什么？](#user-content-2不同层次的卷积都提取什么类型的特征)
- [3.Transformer的优缺点](#user-content-3卷积核大小如何选取)
- [4.Encoder端和Decoder端是如何进行交互？](#user-content-4卷积感受野的相关概念)
- [5.Transformer中为什么需要线性变换？](#user-content-5网络每一层是否只能用一种尺寸的卷积核)
- [6.Transformer attention的注意力矩阵的计算为什么用乘法而不是加法?](#user-content-611卷积的作用)
- [7.transformer中的attention为什么scaled?](#user-content-7转置卷积的作用)
- [8.Transformer attention计算注意力矩阵的时候如何对padding做mask操作的？](#user-content-8空洞卷积的作用)
- [9. Transformer的残差结构及意义](#user-content-9什么是转置卷积的棋盘效应)
- [10.Transformer为什么使用LN而不是BN？](#user-content-10什么是有效感受野)
- [11.Decoder阶段的多头自注意力和encoder的多头自注意力有什么区别？/ 为什么decoder自注意力需要进行sequence mask？](#user-content-11分组卷积的相关知识)
- [12.Transformer的并行化体现在哪里，Decoder可以做并行化m吗？](#user-content-1卷积有什么特点)
- [13.Transformer计算量最大的部分是哪里？](#user-content-2不同层次的卷积都提取什么类型的特征)
- [14.Transformer、LSTM和单纯的前馈神经网络比，有哪些提升？](#user-content-3卷积核大小如何选取)
- [15.有哪些处理超长文本的方法？](#user-content-5网络每一层是否只能用一种尺寸的卷积核)
- 

## 二、Attention机制，Transformer面试问题参考答案

<h1 id="1.Transformer Encoder 有什么子层？">1.Transformer Encoder 有什么子层？</h1>

Transformer 编码器（Encoder）由六个相同层构成，，每层的主要子层包括两个部分：
多头自注意力机制（Multi-Head Self-Attention Mechanism）：这一层允许编码器查看输入序列中的其他位置来更好地编码一个单词。它由多个头组成，每个头独立地学习输入数据的不同方面。
前馈神经网络（Feed-Forward Neural Network）（Linear+relu+dropout+Linear）：这是一个简单的全连接神经网络，它对每个位置的注意力向量进行处理，但是对不同位置是独立的。
除了这些主要子层，还有一些重要的组件：
层归一化（Layer Normalization）：在多头自注意力机制和前馈神经网络之后，通常会有层归一化步骤，以稳定网络的学习过程。
残差连接（Residual Connections）：在每个子层之后，都会加上一个残差连接，然后进行层归一化。残差连接有助于避免在网络中出现梯度消失的问题。
这种结构的组合使得Transformer编码器非常有效且灵活，适用于处理各种顺序数据任务。

<h1 id="2.Transformer self-attentio公式是什么？">2.Transformer self-attention的公式是什么？</h1>

$Attention(Q,K,V)=Softmax(\frac{QK^T}{\sqrt{d_k}})V$

<h1 id="3.Transformer的优缺点有哪些？">3.Transformer的优缺点有哪些？</h1>

优点
具有并行处理能力：与基于循环的模型（如LSTM和GRU）相比，Transformer可以并行处理整个序列，大大提高了训练效率。
长距离依赖：借助多头自注意力机制，Transformer能够有效捕捉序列中长距离的依赖关系，这对于理解文本等复杂序列数据至关重要。
灵活性和泛化能力：Transformer模型在多种任务上都表现出色，包括机器翻译、文本生成、语音识别等。
可扩展性：Transformer模型可以通过增加层数来提高其复杂性和学习能力，使其适用于大规模数据集和复杂任务。
更好的性能：在许多NLP任务中，Transformer模型超越了以往的技术，设立了新的性能标准。
缺点
计算资源密集：尽管Transformer允许并行化，但其自注意力机制涉及大量的计算，对计算资源（尤其是内存）的需求很高。
可解释性不足：与某些传统模型相比，Transformer的决策过程更难解释和理解。
过拟合风险：Transformer模型因其大量的参数而容易过拟合，尤其是在数据较少的情况下。
训练需要精心调优：由于模型的复杂性，找到最佳的训练参数（如学习率、层数、头数等）可能需要大量的实验和调整。
长序列挑战：尽管Transformer在处理长距离依赖方面表现出色，但处理非常长的序列时，性能可能会下降，因为自注意力机制的计算成本随序列长度的增加而显著增加。
总的来说，尽管Transformer有一些局限性，但其在处理复杂序列任务方面的优势使其成为当前最流行和最有效的深度学习架构之一。
局部信息的获取不如RNN和CNN强：Transformer关注的全局关系，而RNN在计算过程中更关注局部，对距离更加敏感。

<h1 id="4.Encoder端和Decoder端是如何进行交互的？">4.Encoder端和Decoder端是如何进行交互的？</h1>

在 Transformer 模型中，编码器（Encoder）和解码器（Decoder）通过一个特殊的注意力机制进行交互，这个机制通常被称为 "编码器-解码器注意力" 或 "交叉注意力"（Cross-Attention）。以下是这种交互的详细步骤：

1. **编码器处理输入序列**：编码器首先处理输入序列，通过自注意力和前馈网络生成一系列上下文表示。这些表示包含了输入序列中每个元素的信息，以及它们之间的相对关系。
2. **解码器自注意力层**：在解码器端，每个解码器层首先通过自注意力机制处理先前生成的输出（例如，在序列生成任务中的先前生成的单词）。这个过程与编码器中的自注意力相似，但有一个关键差异：为了保证自回归属性（即只能使用当前位置之前的信息），解码器在自注意力计算中应用了掩码（masking）。
3. **交叉注意力层**：这是编码器和解码器交互的关键部分。在这一层，解码器的每个元素（或步骤）会对编码器的所有输出进行注意力计算。简而言之，解码器在生成每个元素时都会考虑整个输入序列的上下文信息。

- **查询（Query）**：来自解码器的表示。
- **键（Key）和值（Value）**：来自编码器的表示。

<h1 id="Transformer中为什么需要线性变换？？">5.Transformer中为什么需要线性变换？？</h1>

K、Q、V分别是输入向量经过不同的线性变换矩阵$W_k$、$Q_k$、$V_k$计算得到。
在$QK^T$部分，线性变换矩阵将KQ投影到了不同的空间，增加了表达能力（这一原理可以同理SVM中的核函数-将向量映射到高维空间以解决非线性问题），这样计算得到的注意力矩阵的泛化能力更高。

<h1 id="6.Transformer attention的注意力矩阵的计算为什么用乘法而不是加法？">6.Transformer attention的注意力矩阵的计算为什么用乘法而不是加法？</h1>

Transformer attention的注意力矩阵的计算用乘法是为了计算速度更快。
在计算复杂度上，乘法和加法理论上的复杂度相似，但是在实践中，乘法可以利用高度优化的矩阵乘法代码（有成熟的加速实现）使得点乘速度更快，空间利用率更高。（论文P4有解释）

<h1 id="7.transformer中的attention为什么scaled?">7.transformer中的attention为什么scaled?</h1>

因为虽然矩阵加法的计算更简单，但是 Add形式套着tanh和V，相当于一个完整的隐层。在整体计算复杂度上两者接近，但是矩阵乘法已经有了非常成熟的加速实现。在 $d_k$（即 attention-dim）较小的时候，两者的效果接近。但是随着  $d_k$增大，Add 开始显著超越 Mul。

极大的点积值将整个 softmax 推向梯度平缓区，使得收敛困难。也就是出现了高赞答案里解释的“梯度消失”。

这才有了 scaled。所以，Add 是天然地不需要 scaled，Mul 在 较大的时候必须要做 scaled。个人认为，Add 中的矩阵乘法，和 Mul 中的矩阵乘法不同。前者中只有随机变量 X 和参数矩阵 W 相乘，但是后者中包含随机变量 X 和 随机变量 X 之间的乘法。

参考链接：https://www.zhihu.com/question/339723385

<h1 id="8.Transformer attention计算注意力矩阵的时候如何对padding做mask操作的？">8.Transformer attention计算注意力矩阵的时候如何对padding做mask操作的？</h1>

padding位置置为-1000，再对注意力矩阵进行相加。

<h1 id="9.介绍一下Transformer的残差结构及意义">9.介绍一下Transformer的残差结构及意义</h1>

Transformer 模型中的残差连接（Residual Connection）是一种重要的网络结构设计，它直接将某一层的输入添加到后面层的输出上。以下是残差结构的介绍及其意义：

### 残差结构的介绍

在 Transformer 中，每个编码器和解码器层都包含残差连接。具体来说，对于一个给定的层（比如自注意力层或前馈神经网络层），其处理过程可以总结为：

1. **层内处理**：输入首先通过层内的主要操作（如自注意力或前馈神经网络）。
2. **加上残差**：将这个操作的原始输入直接加到操作的输出上。
3. **层归一化**：在大多数情况下，加法操作之后会接一个层归一化（Layer Normalization）步骤。

这种结构可以表示为：$Output =Normalize(Layer(x) + x)$，其中Layer(x)表示层的操作， x  是输入。

### 残差结构的意义

1. **缓解梯度消失问题**：深度神经网络中常见的问题之一是梯度消失，这会使得训练过程变得困难。残差连接允许梯度直接流过网络，有助于保持梯度的稳定性，从而缓解梯度消失问题。
2. **加速收敛**：由于残差连接的帮助，网络可以更快地学习，加速收敛过程。这是因为它允许网络在训练早期阶段更有效地传播信息和梯度。
3. **促进深层网络训练**：残差连接使得构建更深层的网络变得可行，因为它们减少了训练过程中的复杂性和困难。
4. **保留信息**：残差连接确保了即使经过多个层的处理，输入信息也不会被完全替代或丢失。这在处理长序列时尤其重要，因为信息需要在整个网络中有效传递。
5. **支持特征重用**：残差连接通过将较低层的特征直接传递到后面的层，支持了特征的重用。这意味着网络可以学习使用并重用早期层的特征，而不是每次都重新学习。

总的来说，Transformer 中的残差连接是提高模型性能、稳定性和训练效率的关键设计之一。它们使得深层网络的训练成为可能，同时也确保了信息在网络中的有效传递。

<h1 id="10.Transformer为什么使用LN而不是BN？">10.Transformer为什么使用LN而不是BN？</h1>

Transformer 模型选择使用层归一化（Layer Normalization, LN）而不是批归一化（Batch Normalization, BN）的决策，主要是基于这两种归一化技术的不同特性和在处理序列数据时的适用性考虑：

1. **独立于批大小**：
- **LN**：层归一化对每个样本独立进行，不依赖于批大小。这使得 LN 在处理不同长度的序列或小批量数据时表现更稳定。
- **BN**：批归一化依赖于整个批次的数据统计信息。在小批量数据或批量大小变化时，BN 的效果可能会受到影响。

2. **序列数据的动态长度**：
- 在处理序列数据（特别是长度不一的序列）时，LN 的独立性使其更适合。因为 BN 需要整个批次的数据统计，不同长度的序列可能会导致统计信息不准确。

3. **计算效率**：
- LN 可以在单个样本级别上进行计算，这对于自然语言处理中常见的动态长度序列特别有用。另一方面，BN 需要在批次级别上进行计算，可能不适合长度变化大的序列。

4. **训练和推理一致性**：
- BN 在训练和推理阶段的行为不同（训练时使用当前批次的统计信息，推理时使用整个数据集的统计信息）。这可能导致不确定性。而 LN 在训练和推理时的行为是一致的，因为它总是基于单个样本进行归一化。

5. **内存效率**：
- 在处理大规模序列数据时，使用 BN 可能会增加内存消耗，因为需要存储整个批次的统计信息。LN 由于其样本独立的特性，在这方面更加高效。

总结来说，层归一化因其与批大小无关、适合处理动态长度序列、以及在训练和推理阶段行为一致等优点，被认为是在 Transformer 架构中处理序列数据的更合适的选择。

<h1 id="11.Decoder阶段的多头自注意力和encoder的多头自注意力有什么区别？/ 为什么decoder自注意力需要进行sequence mask？">11.Decoder阶段的多头自注意力和encoder的多头自注意力有什么区别？/ 为什么decoder自注意力需要进行sequence mask？</h1>

在 Transformer 模型中，编码器（Encoder）和解码器（Decoder）的多头自注意力机制在基本原理上是相似的，但在实际应用中存在几个关键的区别：

### 1. 遮蔽（Masking）的应用

- **编码器多头自注意力**：在编码器中的多头自注意力机制不使用遮蔽。这意味着在计算每个元素的注意力时，它可以看到输入序列中的所有其他元素。

- **解码器多头自注意力**：解码器中的多头自注意力机制使用了所谓的 "前瞻遮蔽"（Look-ahead Masking）或 "因果遮蔽"（Causal Masking）。这种遮蔽确保在预测一个元素时，只能使用该元素之前的元素信息，从而避免信息的未来泄露。这对于序列生成任务（如文本生成）至关重要，因为在生成当前词时，模型不应该知道后续的词。

### 2. 关注点的不同

- **编码器多头自注意力**：编码器的自注意力层主要关注的是如何对输入数据中的元素进行编码，包括元素之间的关系和上下文信息。

- **解码器多头自注意力**：解码器的自注意力层则更加关注于已生成的输出序列，即如何基于目前已生成的序列内容来决定下一个元素。

### 3. 输入来源的不同

- **编码器多头自注意力**：编码器的自注意力层处理的输入来自于原始输入序列（例如，待翻译的句子）。

- **解码器多头自注意力**：解码器的自注意力层处理的输入来自于之前的解码器输出（例如，在文本生成任务中，之前生成的文本序列）。

### 4. 解码器中额外的交叉注意力层

- 虽不直接是自注意力的一部分，但值得一提的是，解码器中除了自注意力层之外，还包含了交叉注意力层（也是多头注意力），其中解码器利用编码器的输出来进一步指导生成过程。这是解码器和编码器之间唯一的直接交互，也是解码器结构的一个重要组成部分。

总结来说，尽管编码器和解码器在多头自注意力的基本机制上是相似的，但它们在遮蔽方式、关注点以及输入来源方面存在显著的区别，这些区别使得它们能够适应各自的角色和任务需求。解码器（Decoder）中的自注意力机制需要进行序列遮蔽（sequence masking），主要是为了实现两个目的：防止信息的未来泄露（Future Information Leakage）和保持自回归特性（Autoregressive Property）。

<h1 id="12.Transformer的并行化体现在哪里，Decoder可以做并行化嘛？">12.Transformer的并行化体现在哪里，Decoder可以做并行化嘛？</h1>

Encoder的模块是串行的，但模块内的子模块多头注意力和前馈网络内部都是并行的，因为单词之间没有依赖关系。
Decode引入sequence mask就是为了并行化训练，推理过程不并行

<h1 id="13.Transformer计算量最大的部分是哪里?">13.Transformer计算量最大的部分是哪里？</h1>

在 Transformer 模型中，计算量最大的部分通常是多头自注意力（Multi-Head Self-Attention）机制。这是因为自注意力涉及到对序列中的每个元素与序列中的所有其他元素进行比较，这种全序列对全序列的操作在计算上是非常昂贵的。以下是自注意力机制中计算量大的几个方面：

1. **点积注意力计算**：在自注意力机制中，对于每个元素，都需要计算其与序列中所有其他元素的点积。这种全对全的操作导致计算量随序列长度的平方增长。

2. **线性变换**：在计算注意力之前和之后，需要对查询（Query）、键（Key）和值（Value）进行线性变换。这些变换本身也是计算密集型的，尤其是当模型的维度和头数较大时。

3. **多头注意力**：Transformer 中使用的是多头注意力机制，这意味着上述计算需要被复制多次（每个头一次），进一步增加了总体计算量。

4. **缩放因子的应用**：在计算点积后，还需要应用一个缩放因子（通常是维度的平方根的倒数），虽然这部分计算量相对较小，但也是计算过程的一部分。

5. **Softmax 计算**：计算完点积后，还需要对每个元素的分数应用 softmax 函数以获得最终的注意力权重。这个过程涉及到指数和归一化步骤，对于长序列来说也是计算密集型的。

虽然其他部分，如前馈网络（Feed-Forward Network）和层归一化（Layer Normalization）也需要计算资源，但与多头自注意力相比，它们通常占据的计算量较小。特别是在处理长序列时，自注意力机制的计算量成为模型中的主要瓶颈。



<h1 id="14.Transformer、LSTM和单纯的前馈神经网络比，有哪些提升？">14.Transformer、LSTM和单纯的前馈神经网络比，有哪些提升？</h1>

LSTM相比于单纯的前馈神经网络，首先具有理解文本的语序关系的能力（RNN）。除此之外，又解决了RNN在处理长序列时发生的梯度消失和梯度爆炸的问题。
Transformer进一步解决了RNN、LSTM等模型的长距离依赖问题，能够理解更长的上下文语义。可以并行化，所要的训练时间更短。


<h1 id="15.有哪些处理超长文本的方法？">15.有哪些处理超长文本的方法？</h1>

处理超长文本是自然语言处理（NLP）中的一个挑战，尤其是在使用标准的 Transformer 模型时，因为它们通常对输入序列的长度有限制。以下是一些处理超长文本的常用方法：

### 1. 分段处理（Chunking）
将长文本分割成较小的段落或句子，并分别处理每个部分。这种方法简单直接，但可能会丢失跨段落的上下文信息。

### 2. 层次化注意力（Hierarchical Attention）
在这种方法中，模型首先在较低层次（如句子或段落级别）处理文本，然后在更高层次上整合这些信息。这种方法可以捕捉更广泛的上下文，但实现相对复杂。

### 3. 长序列Transformer变体
一些专门为长序列设计的Transformer变体，如 Transformer-XL, Reformer, Longformer, Big Bird 等，通过改进注意力机制或内存管理机制来处理更长的文本。

- **Transformer-XL**：使用循环机制和相对位置编码来处理长序列。
- **Reformer**：使用局部敏感哈希（Locality-Sensitive Hashing, LSH）注意力和可逆层来减少计算和内存需求。
- **Longformer**：引入了局部窗口式的自注意力机制，并结合了全局注意力，使其能够处理长文本。
- **Big Bird**：采用了稀疏注意力机制，结合随机、局部和全局注意力。

### 4. 滑动窗口（Sliding Window）
使用滑动窗口在文本上进行局部注意力计算，窗口可以重叠以保持一些上下文信息。每个窗口作为一个独立的序列进行处理。

### 5. 稀疏注意力机制
在这种方法中，只计算注意力矩阵的一个稀疏子集，而不是完整的序列对序列注意力。这可以显著减少计算量。

### 6. 提取关键信息
使用文本摘要或关键词提取技术来缩减文本长度，只保留最重要的信息。这种方法适用于某些特定的应用场景。

### 7. 多任务学习
通过将超长文本处理作为一个辅助任务，在多任务学习框架下训练模型。例如，可以将文本摘要作为一个任务，来帮助模型学习如何提取关键信息。

### 8. 利用外部知识库
结合外部知识库，例如使用实体链接或知识图谱，减少模型需要直接从文本中学习的信息量。

每种方法都有其优点和限制，选择哪一种方法取决于特定的应用场景和需求。在实际应用中，可能需要根据具体任务进行方法的调整和优化。


其他参考链接：https://blog.csdn.net/valleria/article/details/105311340



