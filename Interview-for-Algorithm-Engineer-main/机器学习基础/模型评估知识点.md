# 目录

- [1.Accuracy、Precision、Recall、F1 Scores的相关概念？](#user-content-1.accuracy、precision、recall、f1-scores的相关概念？)
- [2.K折交叉验证逻辑？](#user-content-2.k折交叉验证逻辑？)

<h2 id="1.accuracy、precision、recall、f1-scores的相关概念？">1.Accuracy、Precision、Recall、F1 Scores的相关概念？</h2>

首先Rocky介绍一下相关名词：

1. TP（True Positive）: 预测为正，实际为正
2. FP（False Positive）: 预测为正，实际为负
3. TN（True Negative）：预测为负，实际为负
4. FN（false negative）: 预测为负，实际为正

Accuracy、Precision、Recall、F1 Scores的公式如下所示：

![](https://files.mdnice.com/user/33499/6a0d964a-f67f-41b4-ba23-60974dc15420.png)

Accuracy（准确率）：分类正确的样本数占样本总数的比例。

Precision（精准度/查准率）：当前预测为正样本类别中被正确分类的样本比例。

Recall（召回率/查全率）：预测出来的正样本占正样本总数的比例。

F1-score是Precision和Recall的综合。F1-score越高，说明分类模型越稳健。

<h2 id="2.k折交叉验证逻辑？">2.K折交叉验证逻辑？</h2>

### k折交叉验证的作用

当有多个不同的模型（结构不同、超参数不同等）可以选择时，我们通过K折交叉验证来选取对于特定数据集最好的模型。

### k折交叉验证的流程

1. 将含有 $N$ 个样本的数据集，分成 $K$ 份，每份含有 $\frac{N}{K}$ 个样本。选择其中一份作为验证集，另外 $K-1$ 份作为训练集，验证集集就有 $K$ 种情况。
2. 在每种情况中，用训练集训练模型，用验证集测试模型，计算模型的泛化误差。
3. 交叉验证重复 $K$ 次，平均 $K$ 次的结果作为模型最终的泛化误差。
4. $K$ 的取值一般在 $[2，10]$ 之间。 $K$ 折交叉验证的优势在于，同时重复运用随机产生的子样本进行训练和验证， $10$ 折交叉验证是最常用的。
5. 训练集中样本数量要足够多，一般至少大于总样本数的50%。
6. 训练集和验证集必须从完整的数据集中均匀采样。均匀采样的目的是希望减少训练集、验证集与原数据集之间的偏差。当样本数量足够多时，通过随机采样，便可以实现均匀采样的效果。

### 5折交叉验证举例

5折交叉验证(5-fold cross-validation)用来验证从不同的模型中选取最优的模型（最合适的模型）。将数据集分成5份，轮流将其中4份作为训练数据，1份作为验证数据，进行试验。每次试验都会得出相应的正确率。**5次的结果的正确率的平均值作为对算法精度的估计**。同时对不同的模型（如CNN、SVM、LR等）做上述相同的操作，得出每个模型在特定数据集上的平均能力，从中选优。

**例子：**

假设我们有一个特定数据集，我们想从YOLOv4、Mask R-CNN、SSD、Faster R-CNN、RetinaNet这五个模型中选取在这个特定数据集中有最好效果的一个模型作为baseline，我们可以进行交叉验证来进行判断：

**步骤：**

1. 将数据集分成5份。
2. 对于每一个模型，for i = 1， 2， 3， 4，5，每个for循环里将除了第i份的所有数据作为训练集用于训练，得到参数；再将参数在第i份数据上进行验证，得到评价结果。
3. 最后我们可以得到5个模型的结果，每个模型有5个验证结果。将每个模型的结果取平均值，得到该模型的平均结果。
4. 5个模型中平均结果最好的模型就是我们想要的最优模型。
